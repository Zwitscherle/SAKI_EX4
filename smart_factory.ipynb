{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('saki4': venv)"
  },
  "interpreter": {
   "hash": "ad4ad34c08212da66dc6d04eda780af769d3ee710939179ad84caa50910b2cc9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "This is the Smart Factory Exercise."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdptoolbox, mdptoolbox.example\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "source": [
    "Define all items, states and actions of our model. <br>\n",
    "* We have three different items (WHITE, BLUE, RED)\n",
    "* We have four different possible states of each warehouse field (EMPTY, WHITE, BLUE, RED)\n",
    "* We have six possible actions for our agent (STORE and RESTORE in combination with each item color)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['WHITE', 'BLUE', 'RED']\n['WHITE', 'BLUE', 'RED', 'EMPTY']\n[('STORE', 'WHITE'), ('STORE', 'BLUE'), ('STORE', 'RED'), ('RESTORE', 'WHITE'), ('RESTORE', 'BLUE'), ('RESTORE', 'RED')]\n"
     ]
    }
   ],
   "source": [
    "items = ['WHITE', 'BLUE', 'RED']\n",
    "fieldStatus = ['WHITE', 'BLUE', 'RED', 'EMPTY']\n",
    "operations = ['STORE', 'RESTORE']\n",
    "actions = []\n",
    "for operation in operations:\n",
    "    for item in items:\n",
    "        actions.append((operation, item))\n",
    "\n",
    "# warehouse size n x n (in our case n = 2)\n",
    "n = 2\n",
    "print(items)\n",
    "print(fieldStatus)\n",
    "print(actions)"
   ]
  },
  {
   "source": [
    "Create all fields of the warehouse of size lenght x heigth (in our case 2 x 2)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0, 0), (0, 1), (1, 0), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "def createWarehouseFields(length, height):\n",
    "    warehouseFields = []\n",
    "    for i in range(0, length):\n",
    "        for j in range(0, height):\n",
    "            warehouseFields.append((i,j))\n",
    "    return warehouseFields\n",
    "\n",
    "warehouseFields = createWarehouseFields(n, n)\n",
    "print(warehouseFields)"
   ]
  },
  {
   "source": [
    "Next create all possible states of our warehouse. \n",
    "In our case we have 4 fields with 4 different states each (EMPTY, WHITE, BLUE, RED), which results in 4^4 states."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "def getStates(warehouseFields, fieldStatus):  \n",
    "    return itertools.product(fieldStatus, repeat=len(warehouseFields))\n",
    "\n",
    "iterStates = getStates(warehouseFields, fieldStatus)\n",
    "states = []\n",
    "for state in iterStates:\n",
    "  states.append(list(state))\n",
    "\n",
    "print(len(states))"
   ]
  },
  {
   "source": [
    "Create a reward which fits our problem. <br>\n",
    "The reward is higher if the distance our agent has to cover is lower."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.25180384 0.24336554 0.50483062]\n[(0, 0), (0, 1), (1, 0), (1, 1)]\n[1.0, 0.25, 0.25, 0.1111111111111111]\n"
     ]
    }
   ],
   "source": [
    "# read statistics from file to calculate better rewards\n",
    "# i = 0: White, i = 1: Blue, i = 2: Red\n",
    "countItems = np.zeros((3))\n",
    "itemsTotal = 0\n",
    "\n",
    "warehouseorder = open('Exercise4_warehousetraining2x2.txt')\n",
    "for line in warehouseorder:\n",
    "    curAction = line.split('\\t')\n",
    "    # curOperation = curAction[0].upper()\n",
    "    curItem = curAction[1].strip('\\n').upper()\n",
    "    if curItem == 'WHITE':\n",
    "        countItems[0] += 1\n",
    "    if curItem == 'BLUE':\n",
    "        countItems[1] += 1\n",
    "    if curItem == 'RED':\n",
    "        countItems[2] += 1\n",
    "    itemsTotal += 1\n",
    "\n",
    "# i = 0: White, i = 1: Blue, i = 2: Red\n",
    "probsItems = countItems / itemsTotal\n",
    "print(probsItems)\n",
    "\n",
    "# reward function based on distance and item probability:\n",
    "def getRewardBasedOnDistanceAndProbability(fieldIndex, item):\n",
    "    x = warehouseFields[fieldIndex]\n",
    "    distance = x[0] + x[1] + 1\n",
    "    prob = 0\n",
    "    if item == 'WHITE':\n",
    "        prob = probsItems[0]\n",
    "    if item == 'BLUE':\n",
    "        prob = probsItems[1]\n",
    "    if item == 'RED':\n",
    "        prob = probsItems[2]\n",
    "    reward = 1/distance * 1/distance * prob\n",
    "    return reward\n",
    "\n",
    "\n",
    "# simple reward function:\n",
    "# get the distance in field from 0,0 (0,0 has already distance 1)\n",
    "# reward is the reciprocal**2 (to punish far away fields even more)\n",
    "def getRewardBasedOnDistance(x):\n",
    "    distance = x[0] + x[1] + 1\n",
    "    reward = 1/distance * 1/distance\n",
    "    return reward\n",
    "\n",
    "rewardVector = [getRewardBasedOnDistance(x) for x in warehouseFields]\n",
    "print(warehouseFields)\n",
    "print(rewardVector)"
   ]
  },
  {
   "source": [
    "Bring it all together now and create the transition and the reward matrix. <br>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(6, 256, 256)\n1536.0\n"
     ]
    }
   ],
   "source": [
    "# create Transition and reward matrix\n",
    "def createTransitionAndRewardMatrix(actions, states):\n",
    "    T = np.zeros((len(actions), len(states), len(states)))\n",
    "    R = np.zeros((len(states), len(actions)))\n",
    "\n",
    "    for i in range(len(actions)):\n",
    "        # current operation and item\n",
    "        operation, item = actions[i]\n",
    "\n",
    "        for j in range(len(states)):\n",
    "            curState = states[j]\n",
    "\n",
    "            # if an operation is not valid i.e. store when warehouse is full \n",
    "            # or restore when warehouse is empty, stay in the current state \n",
    "            if ((operation == 'STORE') and ('EMPTY' not in curState)) \\\n",
    "                or ((operation == 'RESTORE') and (item not in curState)):\n",
    "                T[i, j, j] = 1                \n",
    "            else:\n",
    "                possibleFields = []\n",
    "                for k in range(len(curState)):\n",
    "                    # find empty fields where the agent can store the item\n",
    "                    if operation == 'STORE':\n",
    "                        if curState[k] == 'EMPTY':\n",
    "                            possibleFields.append(k)\n",
    "                    # find fields with the requested item\n",
    "                    else:\n",
    "                        if curState[k] == item:\n",
    "                            possibleFields.append(k)\n",
    "                # possible fields can not be empty because of the check above\n",
    "                transitionProbability = 1 / len(possibleFields)\n",
    "                # set probabiltiy in transition matrix for the possible nextStates\n",
    "                for field in possibleFields:\n",
    "                    nextState = curState.copy()\n",
    "                    if operation == 'STORE':\n",
    "                        nextState[field] = item\n",
    "                    else:\n",
    "                        nextState[field] = 'EMPTY'\n",
    "                    nextIndex = states.index(nextState)\n",
    "                    T[i, j, nextIndex] = transitionProbability\n",
    "                    # set reward in R\n",
    "                    # R[nextIndex][i] = rewardVector[field] # old simple reward\n",
    "                    R[nextIndex][i] = getRewardBasedOnDistanceAndProbability(field, item)         \n",
    "    return T, R\n",
    "\n",
    "T, R = createTransitionAndRewardMatrix(actions, states)\n",
    "print(np.shape(T))\n",
    "test = np.sum(T)\n",
    "print(test)"
   ]
  },
  {
   "source": [
    "Finally create the mdp models and evaluate the different classes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PolicyIteration:\n(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 0, 5, 5, 5, 0, 5, 5, 5, 2, 0, 0, 2, 0, 5, 5, 5, 0, 5, 5, 5, 1, 5, 5, 5, 2, 1, 1, 2, 1, 5, 5, 5, 2, 5, 5, 5, 2, 5, 5, 5, 2, 2, 2, 2, 2, 0, 0, 2, 0, 1, 1, 2, 1, 2, 2, 2, 2, 5, 5, 2, 2)\n(0.35971977148447737, 0.35971977148447737, 0.35971977148447737, 0.3597197714844773, 0.35971977148447737, 0.35971977148447737, 0.35971977148447737, 0.3597197714844773, 0.35971977148447737, 0.35971977148447737, 0.35971977148447737, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.35971977148447737, 0.35971977148447737, 0.35971977148447737, 0.3597197714844773, 0.35971977148447737, 0.35971977148447737, 0.35971977148447737, 0.3597197714844773, 0.35971977148447737, 0.35971977148447737, 0.35971977148447737, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.35971977148447737, 0.35971977148447737, 0.35971977148447737, 0.3597197714844773, 0.35971977148447737, 0.35971977148447737, 0.35971977148447737, 0.3597197714844773, 0.35971977148447737, 0.35971977148447737, 0.35971977148447737, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.3597197714844773, 0.35971977148447737, 0.3476650535474065, 0.3476650535474065, 0.3476650535474065, 0.34766505354740646, 0.3476650535474065, 0.3476650535474065, 0.3476650535474065, 0.34766505354740646, 0.3476650535474065, 0.3476650535474065, 0.3476650535474065, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.3476650535474065, 0.3476650535474065, 0.3476650535474065, 0.34766505354740646, 0.3476650535474065, 0.3476650535474065, 0.3476650535474065, 0.34766505354740646, 0.3476650535474065, 0.3476650535474065, 0.3476650535474065, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.3476650535474065, 0.3476650535474065, 0.3476650535474065, 0.34766505354740646, 0.3476650535474065, 0.3476650535474065, 0.3476650535474065, 0.34766505354740646, 0.3476650535474065, 0.3476650535474065, 0.3476650535474065, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.34766505354740646, 0.7211866035395448, 0.7211866035395448, 0.7211866035395448, 0.7211866035395447, 0.7211866035395448, 0.7211866035395448, 0.7211866035395448, 0.7211866035395447, 0.7211866035395448, 0.7211866035395448, 0.7211866035395448, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395448, 0.7211866035395448, 0.7211866035395448, 0.7211866035395447, 0.7211866035395448, 0.7211866035395448, 0.7211866035395448, 0.7211866035395447, 0.7211866035395448, 0.7211866035395448, 0.7211866035395448, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395448, 0.7211866035395448, 0.7211866035395448, 0.7211866035395447, 0.7211866035395448, 0.7211866035395448, 0.7211866035395448, 0.7211866035395447, 0.7211866035395448, 0.7211866035395448, 0.7211866035395448, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395447, 0.7211866035395446, 0.7211866035395448, 0.7211866035395448, 0.5723566973566974, 0.2250869162633868, 0.7211866035395448, 0.7211866035395448, 0.5723566973566974, 0.2250869162633868, 0.5723566973566974, 0.5723566973566974, 0.5912345672123929, 0.3230708312322109, 0.2250869162633868, 0.2250869162633868, 0.25295546699919963, 0.14394032041090862, 0.7211866035395448, 0.7211866035395448, 0.5723566973566974, 0.2250869162633868, 0.7211866035395448, 0.7211866035395448, 0.5711813623578329, 0.2211691329338388, 0.5711813623578329, 0.5711813623578329, 0.5912345672123929, 0.3230708312322109, 0.2211691329338388, 0.2211691329338388, 0.25295546699919963, 0.13984171631230452, 0.5723566973566974, 0.5723566973566974, 0.5912345672123929, 0.3230708312322109, 0.5711813623578329, 0.5711813623578329, 0.5912345672123929, 0.3230708312322109, 0.6022474516468972, 0.6022474516468972, 0.6022474516468974, 0.3247227638973866, 0.32472276389738663, 0.32472276389738663, 0.32472276389738663, 0.2632708687528521, 0.2250869162633868, 0.2250869162633868, 0.25295546699919963, 0.14394032041090862, 0.2211691329338388, 0.2211691329338388, 0.25295546699919963, 0.13984171631230452, 0.3247227638973866, 0.3247227638973866, 0.32472276389738663, 0.2632708687528521, 0.1802966508848862, 0.1802966508848862, 0.19315550451984081, 0.10806628841738172)\n2\n"
     ]
    }
   ],
   "source": [
    "# 1. Policy Iteration\n",
    "mdpWarehousePolicy = mdptoolbox.mdp.PolicyIteration(T, R, 0.3, max_iter=100)\n",
    "# Run the MDP\n",
    "mdpWarehousePolicy.run()\n",
    "\n",
    "print('PolicyIteration:')\n",
    "print(mdpWarehousePolicy.policy)\n",
    "print(mdpWarehousePolicy.V)\n",
    "print(mdpWarehousePolicy.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Q learning:\n(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 4, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 4, 0, 3, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 1, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n(0.35971977148447465, 0.35076536936884006, 0.3558981381231146, 0.19430364700441224, 0.32653491900060205, 0.1006668448969918, 0.22366042306339773, 0.013908515227750605, 0.345090137645583, 0.006470291766634087, 0.21186538602327354, 0.0027486956885390745, 0.18508453536881833, 0.031562538595430636, 0.06512418880870822, 0.03652492536160184, 0.35710090451426274, 0.05919109290835104, 0.2031214745195257, 0.04515703214135022, 0.275143222435334, 0.12607901870781202, 0.08303343451067742, 0.019944771961467957, 0.12851452070183192, 0.17318474544722778, 0.0, 0.0062868449056165225, 0.04205631920430839, 0.025401935252779305, 0.012825605670189724, 0.0, 0.3586197661903151, 0.014424028396501636, 0.00025011216163987, 0.030182736973892225, 0.11825553190264337, 0.060239349489543, 0.006882065377046463, 0.014131650973525794, 0.3585521158832673, 0.08975733292630894, 0.30744823402046473, 0.10061106233254691, 0.05643571115429105, 0.0022660255524383963, 0.0037114350209772966, 0.0, 0.20750817709020175, 0.02845103850962455, 0.0438449423611735, 0.010051838879816491, 0.02414896003883868, 0.008557568817517501, 0.01039003494987638, 0.005492195563846799, 0.07033827856816957, 0.0032502319364206608, 0.0033323015470436866, 0.0, 0.008768752271795912, 0.0, 0.0, 0.0, 0.08835955095963163, 0.07793720459501342, 0.0, 0.008802630973100146, 0.03218953929544943, 0.05484905273381733, 0.0, 0.0018869255946111685, 0.06720944565604081, 0.022344059191797425, 0.0, 0.002289328922042568, 0.003642566709018224, 0.006938036575099981, 0.0, 0.0, 0.08825994441040742, 0.02982739727031606, 0.0029402224742206924, 0.015635534609973363, 0.0, 0.0, 0.0, 0.0, 0.0, 3.490121837514965e-06, 0.0, 0.0, 0.003262109729457113, 0.00011218009024508125, 0.0, 7.78339487272921e-05, 0.04627997927653748, 0.06078479474476081, 0.0, 0.004401626231922847, 0.0068415029907441345, 0.0, 0.0, 7.740761645557223e-06, 0.0006765840949440454, 0.0, 2.412949227776811e-06, 0.0009805036525127426, 0.0015586557874830347, 0.0012652889554290647, 0.0, 1.4699402971689125e-05, 0.005877117025545827, 0.0052294242759202, 0.0, 0.002769524746560117, 0.0, 0.00010490537517676278, 0.0, 0.0, 0.0020559880272239483, 8.121682511214119e-05, 0.0, 1.530939294309386e-05, 0.0, 0.0, 0.0, 0.0, 0.0761714364667492, 0.19305805395876383, 0.07701453320223074, 0.005307246075048618, 0.017180706138240635, 0.07446924407627291, 0.0009083350323256873, 0.0016828528863402593, 0.06609557748629649, 0.0, 0.01901821622068476, 0.002730127924297521, 0.0018894667158660169, 0.00109832534724891, 0.0012108704602990367, 0.0016141271797380393, 0.0, 0.0, 0.06712645509441785, 0.025989616087027732, 0.005843055959695388, 0.1857503974717691, 0.0, 2.4217487246278206e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0006625954484458215, 0.0007987488117552432, 0.06165942043359075, 1.0321111736090288e-05, 0.0662371248107751, 0.0024580571268169402, 0.4121635970853264, 0.0, 0.24683345697028705, 0.0019450395304907672, 0.0, 0.0, 0.0, 0.0, 0.004416297402229149, 0.0, 0.000760483997289132, 4.2859107694267516e-05, 0.002467242646505058, 0.002711303413425934, 0.008075907888274272, 0.0, 0.0007745890354102997, 0.014075971854769597, 0.01489235775120494, 0.0, 0.000706488086961343, 0.0, 0.0, 0.0, 0.0, 0.0, 1.761451309423519e-05, 0.0, 0.07051625977237169, 0.02414668368081499, 0.06059960371543087, 0.0011994284122345147, 0.0, 0.004936274450674075, 0.0064471196046846525, 0.001824511872277568, 0.054062119294302644, 0.0011854351575773102, 0.005168041408575873, 0.0, 0.009715324452859744, 0.0009639503645038876, 0.0008068416764308007, 0.002583668025334215, 0.01727878924744812, 0.003210286489048814, 0.004668255591752589, 0.0032124527258816423, 0.004908329708854546, 0.0003999613284627428, 0.00027131025273322153, 0.0, 0.0012045632277674617, 0.0014018251948005218, 0.0, 1.9918883185199284e-06, 0.0005713354284216109, 0.0, 0.0, 0.0, 0.01980578974671468, 0.0, 0.000651997916568475, 0.0, 0.0016440733210935066, 0.005148385358882654, 0.008551851597979436, 0.0, 0.005912833500668656, 0.0003465622816559965, 0.0013530997205744365, 0.0009497238439480117, 0.0004994339606620743, 0.0, 0.0, 0.0, 0.008944405242621191, 0.0, 0.0009747837095346252, 0.0016201452940700538, 0.0, 0.01246181473197385, 1.2774117870871006e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.003048310307763765, 0.0, 0.0, 3.0749254337455735e-06)\n"
     ]
    }
   ],
   "source": [
    "# 2. QLearning\n",
    "mdpWarehouseQ = mdptoolbox.mdp.QLearning(T, R, 0.3)\n",
    "# Run the MDP\n",
    "mdpWarehouseQ.run()\n",
    "\n",
    "print('Q learning:')\n",
    "print(mdpWarehouseQ.policy)\n",
    "print(mdpWarehouseQ.V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Value Iteration:\n(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 0, 5, 5, 5, 0, 5, 5, 5, 2, 0, 0, 2, 0, 5, 5, 5, 0, 5, 5, 5, 1, 5, 5, 5, 2, 1, 1, 2, 1, 5, 5, 5, 2, 5, 5, 5, 2, 5, 5, 5, 2, 2, 2, 2, 2, 0, 0, 2, 0, 1, 1, 2, 1, 2, 2, 2, 2, 5, 5, 2, 2)\n(0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.35000733765439646, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.3382780971016265, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.7017145652439769, 0.557764461293873, 0.21049468020056253, 0.7017145652439769, 0.7017145652439769, 0.557764461293873, 0.21049468020056253, 0.557764461293873, 0.557764461293873, 0.577610370551547, 0.3060535648770943, 0.21049468020056253, 0.21049468020056253, 0.235938200644083, 0.13097468509233212, 0.7017145652439769, 0.7017145652439769, 0.557764461293873, 0.21049468020056253, 0.7017145652439769, 0.7017145652439769, 0.5567518649871591, 0.20673963556316496, 0.5567518649871591, 0.5567518649871591, 0.577610370551547, 0.3060535648770943, 0.20673963556316496, 0.20673963556316496, 0.235938200644083, 0.1270930659165953, 0.557764461293873, 0.557764461293873, 0.577610370551547, 0.3060535648770943, 0.5567518649871591, 0.5567518649871591, 0.577610370551547, 0.3060535648770943, 0.5881276751864987, 0.5881276751864987, 0.5881276751864987, 0.3060535648770943, 0.3060535648770943, 0.3060535648770943, 0.3060535648770943, 0.2473670050140638, 0.21049468020056253, 0.21049468020056253, 0.235938200644083, 0.13097468509233212, 0.20673963556316496, 0.20673963556316496, 0.235938200644083, 0.1270930659165953, 0.3060535648770943, 0.3060535648770943, 0.3060535648770943, 0.2473670050140638, 0.17542864131099423, 0.17542864131099423, 0.17725164078105252, 0.09023847376788553)\n3\n"
     ]
    }
   ],
   "source": [
    "# 3. ValueIteration\n",
    "mdpWarehouseValueIter = mdptoolbox.mdp.ValueIteration(T, R, 0.3)\n",
    "# Run the MDP\n",
    "mdpWarehouseValueIter.run()\n",
    "\n",
    "print('Value Iteration:')\n",
    "print(mdpWarehouseValueIter.policy)\n",
    "print(mdpWarehouseValueIter.V)\n",
    "print(mdpWarehouseValueIter.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}